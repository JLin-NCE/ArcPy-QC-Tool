{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JLin-NCE/ArcPy-QC-Tool/blob/main/Jordan_Lin's_Modified_Jupyter_Notebook_Road_Shapefile_Cleanup_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Road Shapefile Cleanup and Segmentation\n",
        "\n",
        "This Jupyter notebook processes road shapefiles, cleans up the data, merges segments based on street names, and then splits them according to a predefined section list.\n",
        "\n",
        "## Configuration:\n",
        "\n",
        "1. Create a directory named \"County Centerline\" in your working environment.\n",
        "\n",
        "2. Upload the contents of this folder into the \"County Centerline\" directory:\n",
        "   https://drive.google.com/drive/folders/1B50TNQ4cgvvveT16-W6xEzlB6zx7GC9U?usp=sharing\n",
        "\n",
        "## Usage:\n",
        "\n",
        "1. Run the notebook cells in order.\n",
        "\n",
        "2. The script will create several output directories:\n",
        "   - Output/Merged Output\n",
        "   - Output/Split Output\n",
        "   - Output/Split Output/Split Shapefile\n",
        "   - Output/Split Output/Split Shapefile/Split Output\n",
        "   - Output/Final Output\n",
        "\n",
        "3. The script processes the input shapefile, merges segments, splits them based on the section list, and generates various output files including shapefiles, Excel files, and KMZ files.\n",
        "\n",
        "4. The final output will be compressed into an \"Output.zip\" file.\n",
        "\n",
        "5. The resulting shapefile is located in the \"Final Output\" directory within the zip file.\n",
        "\n",
        "## Output:\n",
        "\n",
        "- Merged segments (shapefile and Excel)\n",
        "- Split segments (shapefile and KMZ)\n",
        "- Skipped rows (Excel)\n",
        "- Final output shapefile and KMZ\n",
        "\n",
        "## Notes:\n",
        "\n",
        "- The script uses fuzzy matching for street names. Some segments may be skipped if street names are not recognized.\n",
        "- Intersections are used to split road segments. In some cases, the script may fail to find proper intersection points.\n",
        "- Review the \"skipped_rows.xlsx\" file to see which segments were not processed and why.\n",
        "\n",
        "For any issues or improvements, please refer to the code comments or contact the script maintainer."
      ],
      "metadata": {
        "id": "jE71n66Wot8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny4_QTVGp-hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b867cecc-f995-4c4d-c9bf-7ad65787bf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting simplekml\n",
            "  Downloading simplekml-1.3.6.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting haversine\n",
            "  Downloading haversine-2.8.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting thefuzz\n",
            "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.1)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (2024.7.4)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
            "Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading haversine-2.8.1-py2.py3-none-any.whl (7.7 kB)\n",
            "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
            "Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: simplekml\n",
            "  Building wheel for simplekml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplekml: filename=simplekml-1.3.6-py3-none-any.whl size=65859 sha256=430742f67ee476fc77b678dfc3e22a45fd1bc06d6b2d1f4f11d7ee77c47968e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/7c/e6/621a95f24bd1ff987368f1c37881ffe013433ff6b413d87fcb\n",
            "Successfully built simplekml\n",
            "Installing collected packages: simplekml, xmltodict, rapidfuzz, haversine, thefuzz\n",
            "Successfully installed haversine-2.8.1 rapidfuzz-3.9.6 simplekml-1.3.6 thefuzz-0.22.1 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas geopandas xmltodict opencv-python tqdm simplekml haversine geopy shapely numpy thefuzz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GHgFMGkp-hN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import xmltodict\n",
        "import pandas as pd\n",
        "from cmath import inf\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import simplekml\n",
        "import re\n",
        "from haversine import haversine, Unit\n",
        "import geopy\n",
        "import geopy.distance\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "from shapely.geometry import Polygon\n",
        "import numpy as np\n",
        "import ast\n",
        "import simplekml\n",
        "from shapely import wkt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC3T001Rp-hN"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE_FILE = r\"/content/County Centerline/HawaiianGardens-CAMS-0619224.shp\"\n",
        "OUTPUT_SHAPEFILE_DATA_EXCEL_PATH = r\"/content/Output/coordinates.xlsx\"\n",
        "OUTPUT_EXCEL_MARGED_SEGMENTS = r\"/content/Output/marged_segments.xlsx\"\n",
        "OUTPUT_SHAPEFILE_MARGED_SEGMENTS = r\"/content/Output/marged_segments.shp\"\n",
        "OUTPUT_SHAPE_FILE_WITH_COORDINATES = r\"/content/Output/roads_with_coordinates.shp\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"Output/Merged Output\",exist_ok=False)\n",
        "os.makedirs(\"Output/Split Output\",exist_ok=False)\n",
        "os.makedirs(\"Output/Split Output/Split Shapefile\",exist_ok=False)\n",
        "os.makedirs(\"Output/Split Output/Split Shapefile/Split Output\",exist_ok=False)\n",
        "os.makedirs(\"Output/Final Output\",exist_ok=False)"
      ],
      "metadata": {
        "id": "q5-CyO7-D2UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUP6nzsjp-hO"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely.geometry import LineString\n",
        "from pyproj import Transformer\n",
        "\n",
        "# Function to convert EPSG:2229 coordinates to EPSG:4326 (WGS84)\n",
        "def transform_coordinates(line, transformer):\n",
        "    return LineString([transformer.transform(x, y) for x, y in line.coords])\n",
        "\n",
        "def read_shapefile_to_dataframe(shapefile_path):\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    transformer = Transformer.from_crs(\"EPSG:2229\", \"EPSG:4326\", always_xy=True)\n",
        "    gdf['geometry'] = gdf['geometry'].apply(lambda geom: transform_coordinates(geom, transformer))\n",
        "\n",
        "    return gdf\n",
        "\n",
        "# Function to extract required information from a LineString\n",
        "def extract_line_info(line):\n",
        "    begin_latitude, begin_longitude = line.coords[0][1], line.coords[0][0]\n",
        "    end_latitude, end_longitude = line.coords[-1][1], line.coords[-1][0]\n",
        "    middle_points = [(y, x) for x, y in line.coords[1:-1]]\n",
        "    middle_points_str = \"; \".join([f\"{lat},{lon}\" for lat, lon in middle_points])\n",
        "\n",
        "    return begin_latitude, begin_longitude, end_latitude, end_longitude, middle_points_str\n",
        "\n",
        "\n",
        "gdf = read_shapefile_to_dataframe(INPUT_SHAPE_FILE)\n",
        "gdf['BEGIN LATITUDE'], gdf['BEGIN LONGITUDE'], gdf['END LATITUDE'], gdf['END LONGITUDE'], gdf['MIDDLE POINTS'] = zip(*gdf['geometry'].apply(extract_line_info))\n",
        "df_shapefile = pd.DataFrame(gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M1VjmkbxndkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuXZ8QiUp-hO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a79d06f-ca13-446c-e3b8-5d83e505b785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-23e550d21d38>:9: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  gdf_shapefile.to_file(OUTPUT_SHAPE_FILE_WITH_COORDINATES)\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'BEGIN LATITUDE' to 'BEGIN LATI'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'BEGIN LONGITUDE' to 'BEGIN LONG'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'END LATITUDE' to 'END LATITU'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'END LONGITUDE' to 'END LONGIT'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'MIDDLE POINTS' to 'MIDDLE POI'\n",
            "WARNING:fiona._env:Value '33.830839998520304,-118.08212500136158; 33.83091099864648,-118.08207900188232; 33.830979999082516,-118.0820570022386; 33.83101299872415,-118.0820480015422; 33.83105699926722,-118.08204200062623; 33.831092998836354,-118.08204800093195; 33.83111999993978,-118.0820600007498; 33.83114699965754,-118.0820780013233; 33.83116799818912,-118.08210499986197; 33.83119199891881,-118.08214100086195; 33.83121899981875,-118.08218500078635; 33.83125099931333,-118.08226900060133' of field MIDDLE POI has been truncated to 254 characters.  This warning will not be emitted any more for that layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame has been saved to /content/Output/coordinates.xlsx\n",
            "Final shapefile has been saved to /content/Output/roads_with_coordinates.shp\n"
          ]
        }
      ],
      "source": [
        "df_shapefile.to_excel(OUTPUT_SHAPEFILE_DATA_EXCEL_PATH, index=False)\n",
        "\n",
        "print(f\"DataFrame has been saved to {OUTPUT_SHAPEFILE_DATA_EXCEL_PATH}\")\n",
        "\n",
        "\n",
        "# Convert DataFrame back to GeoDataFrame\n",
        "gdf_shapefile = gpd.GeoDataFrame(df_shapefile, geometry='geometry', crs='EPSG:4326')\n",
        "\n",
        "gdf_shapefile.to_file(OUTPUT_SHAPE_FILE_WITH_COORDINATES)\n",
        "\n",
        "print(f\"Final shapefile has been saved to {OUTPUT_SHAPE_FILE_WITH_COORDINATES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF_zwT_9p-hO"
      },
      "source": [
        "### Merge Segments Based on Street Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xLObRd2p-hP"
      },
      "outputs": [],
      "source": [
        "def get_distance(current_location, target_location):\n",
        "    return int(geopy.distance.geodesic(current_location, target_location).feet)\n",
        "\n",
        "def sort_coordinates(ref_point,Coordinates):\n",
        "    #making the tuple of each coordinates enclosed in a list\n",
        "    Coordinates = [tuple(map(float, coord.split(','))) for coord in Coordinates.split(';')]\n",
        "\n",
        "    DistFromBegin = haversine(Coordinates[0], ref_point, unit=Unit.FEET)\n",
        "    DistFromEnd =  haversine(Coordinates[-1], ref_point, unit=Unit.FEET)\n",
        "\n",
        "    MinDist = min (DistFromBegin, DistFromEnd)\n",
        "    if MinDist == DistFromEnd:\n",
        "        Coordinates.reverse()\n",
        "    #Extracting the last point of sorted_coordinates\n",
        "    End_Lat, End_Long = Coordinates[-1][0], Coordinates[-1][1]\n",
        "\n",
        "    Coordinates = Coordinates[0:-1]\n",
        "\n",
        "    #converting to a specific format\n",
        "    L1_mid ='; '.join([f\"{lat},{lon}\" for lat, lon in Coordinates])\n",
        "    return  L1_mid, End_Lat, End_Long\n",
        "\n",
        "def sort_df(dup_id):\n",
        "    dup_id = dup_id.reset_index(drop=True)\n",
        "    distance_dict = {}\n",
        "\n",
        "    P1BegCoords = (float(dup_id.loc[0]['BEGIN LATITUDE']),float(dup_id.loc[0]['BEGIN LONGITUDE']))\n",
        "    P1EndCoords = (float(dup_id.loc[0]['END LATITUDE']),float(dup_id.loc[0]['END LONGITUDE']))\n",
        "    for _index, row in dup_id.iterrows():\n",
        "        if _index == 0:\n",
        "            continue\n",
        "        if _index > len(dup_id)-1:\n",
        "            continue\n",
        "        dist = []\n",
        "        P2BegCoords = (float(dup_id.loc[_index]['BEGIN LATITUDE']),float(dup_id.loc[_index]['BEGIN LONGITUDE']))\n",
        "        P2EndCoords = (float(dup_id.loc[_index]['END LATITUDE']),float(dup_id.loc[_index]['END LONGITUDE']))\n",
        "        dist.append(int(haversine(P2BegCoords, P1BegCoords, unit=Unit.FEET)))\n",
        "        dist.append(int(haversine(P2BegCoords, P1EndCoords, unit=Unit.FEET)))\n",
        "        dist.append(int(haversine(P2EndCoords, P1BegCoords, unit=Unit.FEET)))\n",
        "        dist.append(int(haversine(P2EndCoords, P1EndCoords, unit=Unit.FEET)))\n",
        "        distance_dict[_index] = min(dist)\n",
        "\n",
        "    #sort the dictionary on the bases of values in descending order\n",
        "    sorted_dict = dict(sorted(distance_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "    #getting the keys of the dictionary\n",
        "    new_index = list(sorted_dict.keys())\n",
        "    new_index.append(0)\n",
        "\n",
        "    dup_id = dup_id.reindex(new_index)\n",
        "    dup_id = dup_id.reset_index(drop=True)\n",
        "    return dup_id\n",
        "\n",
        "def  merge_segments(df):\n",
        "    try:\n",
        "        dup_df = pd.concat(g for _, g in df.groupby(\"FullName\") if len(g) > 1)\n",
        "    except:\n",
        "        return df\n",
        "    Repeat_ids = dup_df['FullName'].unique()\n",
        "    new_df = pd.DataFrame(columns=df.columns)\n",
        "    count = 0\n",
        "    for id in Repeat_ids:\n",
        "        dup_id = dup_df.loc[dup_df['FullName']==id]\n",
        "        original_indexes = dup_df.loc[dup_df['FullName']==id]\n",
        "\n",
        "        dup_id = dup_id.reset_index(drop=True)\n",
        "        for i in range(len(dup_id)-1,0,-1):\n",
        "            if len(dup_id) > 2:\n",
        "                dup_id = sort_df(dup_id)\n",
        "            \"\"\"\n",
        "            L0B = Line 0 Begin point\n",
        "            L0E = Line 0 End Point\n",
        "            L1B = Line 1 Begin point\n",
        "            L1E = Line 1 End Point\n",
        "\n",
        "            Remember that Loop is iterating from downward to upward\n",
        "            which means that Line 0(L0B,L0E) is below than Line 1(L1b,L1E) in dataframe\n",
        "            \"\"\"\n",
        "            L0B = tuple(float(x) for x in dup_id.iloc[i][['BEGIN LATITUDE', 'BEGIN LONGITUDE']])\n",
        "            L0E = tuple(float(x) for x in dup_id.iloc[i][['END LATITUDE', 'END LONGITUDE']])\n",
        "            L1B = tuple(float(x) for x in dup_id.iloc[i-1][['BEGIN LATITUDE', 'BEGIN LONGITUDE']])\n",
        "            L1E = tuple(float(x) for x in dup_id.iloc[i-1][['END LATITUDE', 'END LONGITUDE']])\n",
        "\n",
        "            D_L0B_L1B = get_distance(L0B,L1B)\n",
        "            D_L0B_L1E = get_distance(L0B,L1E)\n",
        "            D_L0E_L1B = get_distance(L0E,L1B)\n",
        "            D_L0E_L1E = get_distance(L0E,L1E)\n",
        "\n",
        "            min_dist = min(D_L0B_L1B,D_L0B_L1E,D_L0E_L1B,D_L0E_L1E)\n",
        "\n",
        "            if D_L0E_L1E == min_dist:\n",
        "                Beg_Lat, Beg_Long = L0B\n",
        "                \"\"\"\n",
        "                Combine the Middle points\n",
        "                \"\"\"\n",
        "\n",
        "                ref_point = L0E\n",
        "\n",
        "                L1_coords = str(L1B[0])+\",\"+str(L1B[1])+\"; \"\n",
        "                if dup_id.iloc[i-1]['MIDDLE POINTS'] !=\"\":\n",
        "                    L1_coords += dup_id.iloc[i-1]['MIDDLE POINTS']+\"; \"\n",
        "                L1_coords += str(L1E[0])+\",\"+str(L1E[1])\n",
        "\n",
        "                L1_mid, End_Lat, End_Long = sort_coordinates(ref_point,L1_coords)\n",
        "\n",
        "                if dup_id.iloc[i]['MIDDLE POINTS'] != \"\":\n",
        "                    Mid_points = dup_id.iloc[i]['MIDDLE POINTS'] + \"; \"\n",
        "                else:\n",
        "                    Mid_points = \"\"\n",
        "\n",
        "                Mid_points += str(L0E[0]) + \",\" + str(L0E[1])\n",
        "                if L1_mid !=\"\":\n",
        "                    Mid_points +=\"; \" + L1_mid\n",
        "\n",
        "            elif D_L0E_L1B == min_dist:\n",
        "                Beg_Lat, Beg_Long = L0B\n",
        "\n",
        "                \"\"\"\n",
        "                Combine the Middle points\n",
        "                \"\"\"\n",
        "                ref_point = L0E\n",
        "                L1_coords = str(L1B[0])+\",\"+str(L1B[1])+\"; \"\n",
        "                if dup_id.iloc[i-1]['MIDDLE POINTS'] !=\"\":\n",
        "                    L1_coords += dup_id.iloc[i-1]['MIDDLE POINTS']+\"; \"\n",
        "                L1_coords += str(L1E[0])+\",\"+str(L1E[1])\n",
        "\n",
        "                L1_mid, End_Lat, End_Long = sort_coordinates(ref_point,L1_coords)\n",
        "\n",
        "                if dup_id.iloc[i]['MIDDLE POINTS'] != \"\":\n",
        "                    Mid_points = dup_id.iloc[i]['MIDDLE POINTS'] + \"; \"\n",
        "                else:\n",
        "                    Mid_points = \"\"\n",
        "\n",
        "                Mid_points += str(L0E[0]) + \",\" + str(L0E[1])\n",
        "\n",
        "                if L1_mid !=\"\":\n",
        "                    Mid_points +=\"; \" + L1_mid\n",
        "\n",
        "\n",
        "            elif D_L0B_L1E == min_dist:\n",
        "                Beg_Lat, Beg_Long = L0E\n",
        "\n",
        "                \"\"\"\n",
        "                Combine the Middle points\n",
        "                \"\"\"\n",
        "                if dup_id.iloc[i]['MIDDLE POINTS'] !=\"\":\n",
        "                    L0_mid = dup_id.iloc[i]['MIDDLE POINTS']\n",
        "                    L0_mid = \"; \".join(L0_mid.split(\"; \")[::-1])\n",
        "                    Mid_points =  L0_mid  + \"; \"\n",
        "                else:\n",
        "                    Mid_points = \"\"\n",
        "                ref_point = L0B\n",
        "\n",
        "                L1_coords = str(L1B[0])+\",\"+str(L1B[1])+\"; \"\n",
        "                if dup_id.iloc[i-1]['MIDDLE POINTS'] !=\"\":\n",
        "                    L1_coords += dup_id.iloc[i-1]['MIDDLE POINTS']+\"; \"\n",
        "                L1_coords += str(L1E[0])+\",\"+str(L1E[1])\n",
        "\n",
        "                L1_mid, End_Lat, End_Long = sort_coordinates(ref_point,L1_coords)\n",
        "\n",
        "                Mid_points += str(L0B[0]) + \",\" + str(L0B[1])\n",
        "\n",
        "                if L1_mid !=\"\":\n",
        "                    Mid_points +=\"; \" + L1_mid\n",
        "\n",
        "\n",
        "            elif D_L0B_L1B == min_dist:\n",
        "                Beg_Lat, Beg_Long = L0E\n",
        "\n",
        "                \"\"\"\n",
        "                Combine the Middle points\n",
        "                \"\"\"\n",
        "                if  dup_id.iloc[i]['MIDDLE POINTS'] !=\"\":\n",
        "                    L0_mid = dup_id.iloc[i]['MIDDLE POINTS']\n",
        "                    L0_mid = \"; \".join(L0_mid.split(\"; \")[::-1])\n",
        "                    Mid_points =  L0_mid  + \"; \"\n",
        "                else:\n",
        "                    Mid_points = \"\"\n",
        "\n",
        "                ref_point = L0B\n",
        "\n",
        "                L1_coords = str(L1B[0])+\",\"+str(L1B[1])+\"; \"\n",
        "                if dup_id.iloc[i-1]['MIDDLE POINTS'] !=\"\":\n",
        "                    L1_coords += dup_id.iloc[i-1]['MIDDLE POINTS']+\"; \"\n",
        "                L1_coords += str(L1E[0])+\",\"+str(L1E[1])\n",
        "\n",
        "                L1_mid, End_Lat, End_Long = sort_coordinates(ref_point,L1_coords)\n",
        "\n",
        "                Mid_points += str(L0B[0]) + \",\" + str(L0B[1])\n",
        "\n",
        "                if L1_mid !=\"\":\n",
        "                    Mid_points +=\"; \" + L1_mid\n",
        "\n",
        "            #update duplicate id Dataframe\n",
        "            dup_id.loc[i-1,'BEGIN LATITUDE'] = Beg_Lat\n",
        "            dup_id.loc[i-1,'BEGIN LONGITUDE'] = Beg_Long\n",
        "            dup_id.loc[i-1,'END LATITUDE'] = End_Lat\n",
        "            dup_id.loc[i-1,'END LONGITUDE'] = End_Long\n",
        "            dup_id.loc[i-1,'MIDDLE POINTS'] = Mid_points\n",
        "\n",
        "            df.drop(original_indexes.index[i],inplace=True)\n",
        "            dup_id.drop(i,inplace=True)\n",
        "\n",
        "        df.loc[original_indexes.index[0],'BEGIN LATITUDE'] = Beg_Lat\n",
        "        df.loc[original_indexes.index[0],'BEGIN LONGITUDE'] = Beg_Long\n",
        "        df.loc[original_indexes.index[0],'END LATITUDE'] = End_Lat\n",
        "        df.loc[original_indexes.index[0],'END LONGITUDE'] = End_Long\n",
        "        df.loc[original_indexes.index[0],'MIDDLE POINTS'] = Mid_points\n",
        "\n",
        "        if Mid_points != \"\":\n",
        "            all_coords = str(Beg_Lat)+\",\"+str(Beg_Long)+\"; \"+Mid_points+\"; \"+str(End_Lat)+\",\"+str(End_Long)\n",
        "        else:\n",
        "            all_coords = str(Beg_Lat)+\",\"+str(Beg_Long)+\"; \"+str(End_Lat)+\",\"+str(End_Long)\n",
        "        try:\n",
        "            coordinates = [tuple(map(float, coord.split(','))) for coord in all_coords.split(\"; \")]\n",
        "        except:\n",
        "            coordinates = [tuple(map(float, coord.split(','))) for coord in all_coords.split(\"; \")]\n",
        "        Seg_len = 0\n",
        "        for i in range(1, len(coordinates)):\n",
        "            Seg_len += get_distance(coordinates[i-1], coordinates[i])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzrmnswap-hQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180f35c0-7d7d-4fd9-af8c-973193a389fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-863b95de04e0>:35: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  gdf.to_file(OUTPUT_SHAPEFILE_MERGED_SEGMENTS, driver='ESRI Shapefile')\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'STREET NAME' to 'STREET NAM'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'BEGIN LATITUDE' to 'BEGIN LATI'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'BEGIN LONGITUDE' to 'BEGIN LONG'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'END LATITUDE' to 'END LATITU'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'END LONGITUDE' to 'END LONGIT'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'MIDDLE POINTS' to 'MIDDLE POI'\n",
            "WARNING:fiona._env:Value '33.830839998520304,-118.08212500136158; 33.83091099864648,-118.08207900188232; 33.830979999082516,-118.0820570022386; 33.83101299872415,-118.0820480015422; 33.83105699926722,-118.08204200062623; 33.831092998836354,-118.08204800093195; 33.83111999993978,-118.0820600007498; 33.83114699965754,-118.0820780013233; 33.83116799818912,-118.08210499986197; 33.83119199891881,-118.08214100086195; 33.83121899981875,-118.08218500078635; 33.83125099931333,-118.08226900060133' of field MIDDLE POI has been truncated to 254 characters.  This warning will not be emitted any more for that layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved merged segments to /content/Output/Merged Output/output_excel_merged_segments.xlsx\n",
            "Saved GeoDataFrame to shapefile at /content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.shp\n",
            "KMZ file has been saved to /content/Output/Merged Output/output_merged_segments.kmz\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import LineString\n",
        "import simplekml\n",
        "\n",
        "# Input and output paths\n",
        "INPUT_SHAPE_FILE = r\"/content/County Centerline/HawaiianGardens-CAMS-0619224.shp\"\n",
        "OUTPUT_EXCEL_MERGED_SEGMENTS = r\"/content/Output/Merged Output/output_excel_merged_segments.xlsx\"\n",
        "OUTPUT_SHAPEFILE_MERGED_SEGMENTS = r\"/content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.shp\"\n",
        "OUTPUT_KMZ_MERGED_SEGMENTS = r\"/content/Output/Merged Output/output_merged_segments.kmz\"\n",
        "\n",
        "# Assuming df_shapefile is your original DataFrame and merge_segments is defined somewhere\n",
        "# Merge segments\n",
        "merged_seg = merge_segments(df_shapefile)\n",
        "\n",
        "# Rename the column\n",
        "merged_seg = merged_seg.rename(columns={'FullName': 'STREET NAME'})\n",
        "\n",
        "# Convert STREET NAME to uppercase\n",
        "merged_seg['STREET NAME'] = merged_seg['STREET NAME'].str.upper()\n",
        "\n",
        "# Save merged segments to Excel\n",
        "merged_seg.to_excel(OUTPUT_EXCEL_MERGED_SEGMENTS, index=False)\n",
        "print(f\"Saved merged segments to {OUTPUT_EXCEL_MERGED_SEGMENTS}\")\n",
        "\n",
        "# Create geometry column if not present\n",
        "if 'geometry' not in merged_seg.columns:\n",
        "    merged_seg['geometry'] = merged_seg.apply(lambda row: LineString([(row['BEGIN LONGITUDE'], row['BEGIN LATITUDE']),\n",
        "                                                                      (row['END LONGITUDE'], row['END LATITUDE'])]), axis=1)\n",
        "\n",
        "# Convert DataFrame to GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(merged_seg, geometry='geometry', crs='EPSG:4326')\n",
        "\n",
        "# Save the GeoDataFrame as a shapefile\n",
        "gdf.to_file(OUTPUT_SHAPEFILE_MERGED_SEGMENTS, driver='ESRI Shapefile')\n",
        "print(f\"Saved GeoDataFrame to shapefile at {OUTPUT_SHAPEFILE_MERGED_SEGMENTS}\")\n",
        "\n",
        "# Save the GeoDataFrame as a KMZ file\n",
        "kml = simplekml.Kml()\n",
        "\n",
        "for index, row in gdf.iterrows():\n",
        "    line = kml.newlinestring(name=row['STREET NAME'],\n",
        "                             coords=[(row['BEGIN LONGITUDE'], row['BEGIN LATITUDE']),\n",
        "                                     (row['END LONGITUDE'], row['END LATITUDE'])])\n",
        "    line.style.linestyle.color = simplekml.Color.red  # Change color as needed\n",
        "    line.style.linestyle.width = 2  # Change width as needed\n",
        "\n",
        "    # Add extended data to the placemark\n",
        "    for column_name, value in row.items():\n",
        "        if column_name != 'geometry':\n",
        "            line.extendeddata.schemadata.newsimpledata(column_name, str(value))\n",
        "\n",
        "kml.savekmz(OUTPUT_KMZ_MERGED_SEGMENTS)\n",
        "print(f\"KMZ file has been saved to {OUTPUT_KMZ_MERGED_SEGMENTS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGb0KN0Fp-hQ"
      },
      "source": [
        "### Split the segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khrJH7kGp-hQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e07c297-8019-4343-ecf5-b1fac81ba264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_section has been saved to /content/Output/Split Output/df_section_inspect.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the Excel file\n",
        "SECTION_XLSX = r\"/content/County Centerline/Hawaiian Gardens Section List.xlsx\"\n",
        "\n",
        "# Read the Excel file\n",
        "df_section = pd.read_excel(SECTION_XLSX)\n",
        "\n",
        "# Output the DataFrame to a new Excel file to inspect it\n",
        "output_path = r\"/content/Output/Split Output/df_section_inspect.xlsx\"\n",
        "df_section.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"df_section has been saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w73JcAwMp-hQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f59028-c1bd-4d57-d602-2563a9c8dc87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
            "  return lib.line_locate_point(line, other)\n",
            "WARNING:root:Not enough intersection points found for 214TH, using full line.\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07203556243017 33.837991237295526) to POINT (-118.07203556243017 33.837991237295526)\n",
            "WARNING:root:Not enough intersection points found for 215TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 215TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 215TH, using full line.\n",
            "ERROR:root:Unrecognized street name(s): 215TH, BELSHIRE, CITY LIMITS. Skipping.\n",
            "WARNING:root:Not enough intersection points found for 216TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 216TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 221ST, using full line.\n",
            "WARNING:root:Not enough intersection points found for 221ST, using full line.\n",
            "WARNING:root:Not enough intersection points found for 221ST, using full line.\n",
            "WARNING:root:Not enough intersection points found for 221ST, using full line.\n",
            "WARNING:root:Not enough intersection points found for 221ST, using full line.\n",
            "WARNING:root:Not enough intersection points found for 224TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 224TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 224TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "WARNING:root:Not enough intersection points found for 226TH, using full line.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, BRITTAIN, 224TH. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, 224TH, 223RD. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, 223RD, 222ND. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, 222ND, 221ST. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, TILBURY, 216TH. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY010, 216TH, 215TH. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY060, HORST, ALLEY W/ NORWALK. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY050, HORST, ALLEY W/ NORWALK. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY040, HORST, ALLEY W/ NORWALK. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY030, ARLINE, CLARKDALE. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY030, DEVLIN, ELAINE. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY030, ELAINE, JUAN. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY020, 221ST, CIVIC CENTER. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY020, TILBURY, 216TH. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY020, 216TH, 215TH. Skipping.\n",
            "ERROR:root:Unrecognized street name(s): ALY020, 215TH, 214TH. Skipping.\n",
            "WARNING:root:Not enough intersection points found for ARLIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ARLIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ARLIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for BELSH, using full line.\n",
            "WARNING:root:Not enough intersection points found for BELSH, using full line.\n",
            "WARNING:root:Not enough intersection points found for BELSH, using full line.\n",
            "WARNING:root:Not enough intersection points found for BELSH, using full line.\n",
            "WARNING:root:Not enough intersection points found for BELSH, using full line.\n",
            "ERROR:root:Unrecognized street name(s): BLOOM, CARSON, CITY LIMITS. Skipping.\n",
            "WARNING:root:Not enough intersection points found for CANAD, using full line.\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045622 33.83148132256965) to POINT (-118.07197453045622 33.83148132256965)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045622 33.83148132256965) to POINT (-118.07197453045622 33.83148132256965)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.06764588071742 33.83798707706825) to POINT (-118.06764588071742 33.83798707706825)\n",
            "WARNING:root:Not enough intersection points found for CLARK, using full line.\n",
            "WARNING:root:Not enough intersection points found for CLARK, using full line.\n",
            "WARNING:root:Not enough intersection points found for CLARK, using full line.\n",
            "WARNING:root:Not enough intersection points found for CORTN, using full line.\n",
            "WARNING:root:Not enough intersection points found for DEVLI, using full line.\n",
            "WARNING:root:Not enough intersection points found for DEVLI, using full line.\n",
            "WARNING:root:Not enough intersection points found for ELAIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ELAIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ELAIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ELAIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for ELAIN, using full line.\n",
            "WARNING:root:Not enough intersection points found for FARLO, using full line.\n",
            "WARNING:root:Not enough intersection points found for FUNST, using full line.\n",
            "WARNING:root:Not enough intersection points found for HAWAI, using full line.\n",
            "WARNING:root:Not enough intersection points found for HORST, using full line.\n",
            "WARNING:root:Not enough intersection points found for HORST, using full line.\n",
            "WARNING:root:Not enough intersection points found for HORST, using full line.\n",
            "WARNING:root:Not enough intersection points found for HORST, using full line.\n",
            "WARNING:root:Not enough intersection points found for IBEX, using full line.\n",
            "WARNING:root:Not enough intersection points found for IBEX, using full line.\n",
            "WARNING:root:Not enough intersection points found for IBEX, using full line.\n",
            "WARNING:root:Not enough intersection points found for JOLIE, using full line.\n",
            "WARNING:root:Not enough intersection points found for JOLIE, using full line.\n",
            "WARNING:root:Not enough intersection points found for JOLIE, using full line.\n",
            "WARNING:root:Not enough intersection points found for JUAN, using full line.\n",
            "WARNING:root:Not enough intersection points found for JUAN, using full line.\n",
            "WARNING:root:Not enough intersection points found for JUAN, using full line.\n",
            "WARNING:root:Not enough intersection points found for JUAN, using full line.\n",
            "WARNING:root:Not enough intersection points found for JUAN, using full line.\n",
            "ERROR:root:Unrecognized street name(s): NORWLK, 226TH, S. CITY LIMITS. Skipping.\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07205200077605 33.83872497865596) to POINT (-118.07203556243019 33.83799123729553)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07203556243019 33.83799123729553) to POINT (-118.07203556243019 33.83799123729553)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07203556243019 33.83799123729553) to POINT (-118.07203556243019 33.83799123729553)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045623 33.83148132256967) to POINT (-118.07197453045623 33.83148132256967)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045623 33.83148132256967) to POINT (-118.07197453045623 33.83148132256967)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045623 33.83148132256967) to POINT (-118.07197453045623 33.83148132256967)\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.07197453045623 33.83148132256967) to POINT (-118.07197453045623 33.83148132256967)\n",
            "WARNING:root:Not enough intersection points found for PIONE, using full line.\n",
            "WARNING:root:Not enough intersection points found for PIONE, using full line.\n",
            "WARNING:root:Not enough intersection points found for PIONE, using full line.\n",
            "WARNING:root:Not enough intersection points found for SCHUL, using full line.\n",
            "WARNING:root:Not enough intersection points found for SEINE, using full line.\n",
            "WARNING:root:Not enough intersection points found for SEINE, using full line.\n",
            "WARNING:root:Not enough intersection points found for SEINE, using full line.\n",
            "WARNING:root:Not enough coordinates to split line: from POINT (-118.06980436303309 33.83244593216174) to POINT (-118.0719794007954 33.8323816321293)\n",
            "WARNING:root:Not enough intersection points found for VERNE, using full line.\n",
            "WARNING:root:Not enough intersection points found for VIOLE, using full line.\n",
            "WARNING:root:Not enough intersection points found for VIOLE, using full line.\n",
            "WARNING:root:Not enough intersection points found for VIOLE, using full line.\n",
            "WARNING:root:Not enough intersection points found for WARDH, using full line.\n",
            "WARNING:root:Not enough intersection points found for BLOOM, using full line.\n",
            "<ipython-input-17-f6547d6c864f>:263: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  all_split_lines_gdf.to_file(OUTPUT_MERGED_SHAPEFILE, driver='ESRI Shapefile')\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'StreetID - SectionID' to 'StreetID -'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'STREET NAME' to 'STREET NAM'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Functional Class' to 'Functional'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Surface Type' to 'Surface Ty'\n",
            "WARNING:root:Skipping row 57 with None or empty geometry.\n",
            "WARNING:root:Skipping row 58 with None or empty geometry.\n",
            "<ipython-input-17-f6547d6c864f>:309: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  final_gdf.to_file(output_shapefile_path)\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'StreetID - SectionID' to 'StreetID -'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'STREET NAME' to 'STREET NAM'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Functional Class' to 'Functional'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Surface Type' to 'Surface Ty'\n",
            "WARNING:root:Duplicate geometries found. This may result in fewer rows in the final shapefile.\n",
            "WARNING:root:    STREET NAME                         FROM                             TO\n",
            "0         211TH                      NORWALK                       CLARETTA\n",
            "1         212TH                      NORWALK                       CLARETTA\n",
            "2         213TH                      NORWALK                       CLARETTA\n",
            "3         214TH                       ELAINE                         NORWLK\n",
            "4         214TH                       NORWLK                        NORWALK\n",
            "5         214TH                      NORWALK                       CLARETTA\n",
            "6         215TH  CITY LIMIT (630' E PIONEER)                         ELAINE\n",
            "7         215TH                        HORST                        NORWALK\n",
            "8         215TH                      NORWALK                       BELSHIRE\n",
            "9         216TH                        HORST                        NORWALK\n",
            "10        216TH                      NORWALK                       BELSHIRE\n",
            "11        221ST                      PIONEER                          SEINE\n",
            "12        221ST                        SEINE                           JUAN\n",
            "13        221ST                       JOLIET                        NORWALK\n",
            "14        221ST                      NORWALK                       BELSHIRE\n",
            "15        221ST                     BELSHIRE                       CLARETTA\n",
            "16        221ST                     CLARETTA                       HAWAIIAN\n",
            "17        221ST                     HAWAIIAN                        WARDHAM\n",
            "27        224TH                      NORWALK                       BELSHIRE\n",
            "28        224TH                     BELSHIRE                       CLARETTA\n",
            "29        224TH                     CLARETTA                        WARDHAM\n",
            "30        226TH                      PIONEER                         ARLINE\n",
            "31        226TH                       ARLINE                         DEVLIN\n",
            "32        226TH                       DEVLIN                           JUAN\n",
            "33        226TH                         JUAN                        NORWALK\n",
            "34        226TH                      NORWALK                       BELSHIRE\n",
            "35        226TH                     BELSHIRE                        CORTNER\n",
            "36        226TH                      CORTNER                        WARDHAM\n",
            "37        ARLIN                        226TH                          223RD\n",
            "38        ARLIN                        223RD                          221ST\n",
            "39        ARLIN                        221ST                   CIVIC CENTER\n",
            "41        BELSH                        226TH                       BRITTAIN\n",
            "42        BELSH                     BRITTAIN                          224TH\n",
            "43        BELSH                        224TH                          223RD\n",
            "47        BELSH                       CARSON                          216TH\n",
            "48        BELSH                        216TH                          214TH\n",
            "49        BRITT                      NORWALK                       BELSHIRE\n",
            "50        BRITT                     BELSHIRE                       CLARETTA\n",
            "53        CARSN                      PIONEER                         ARLINE\n",
            "54        CARSN                       ARLINE                        PIONEER\n",
            "55        CARSN                       ARLINE                        VIOLETA\n",
            "56        CARSN                      VIOLETA                         ARLINE\n",
            "57        CARSN                      VIOLETA                           JUAN\n",
            "58        CARSN                         JUAN                        VIOLETA\n",
            "59        CARSN                         JUAN       END AC (400' W/ NORWALK)\n",
            "60        CARSN    BEGIN AC (85' W/ NORWALK)                           JUAN\n",
            "61        CARSN  BEGIN PCC (400' W/ NORWALK)       END PCC (85' E/ NORWALK)\n",
            "62        CARSN  BEGIN PCC (400' E/ NORWALK)       END PCC (85' W/ NORWALK)\n",
            "63        CARSN    BEGIN AC (85' E/ NORWALK)                       BELSHIRE\n",
            "64        CARSN                     BELSHIRE  END AC (400' E/ NORWALK BLVD)\n",
            "65        CARSN                     BELSHIRE                       CLARETTA\n",
            "66        CARSN                     CLARETTA                       BELSHIRE\n",
            "67        CARSN                     CLARETTA                     BLOOMFIELD\n",
            "68        CARSN                   BLOOMFIELD                       CLARETTA\n",
            "73        CLARE                        226TH                       BRITTAIN\n",
            "74        CLARE                     BRITTAIN                          224TH\n",
            "77        CLARE                        222ND                          221ST\n",
            "78        CLARE                        221ST                            END\n",
            "82        CLARK                        226TH                          223RD\n",
            "83        CLARK                        223RD                          221ST\n",
            "84        CLARK                        221ST                   CIVIC CENTER\n",
            "87        DEVLI                        226TH                          223RD\n",
            "88        DEVLI                        221ST                   CIVIC CENTER\n",
            "90        ELAIN                        226TH                          223RD\n",
            "91        ELAIN                        223RD                          221ST\n",
            "92        ELAIN                        221ST                   CIVIC CENTER\n",
            "94        ELAIN                        215TH                          214TH\n",
            "95        ELAIN                        214TH                            END\n",
            "99        HORST                        226TH                          223RD\n",
            "100       HORST                        223RD                          221ST\n",
            "101       HORST                        221ST                   CIVIC CENTER\n",
            "102       HORST                      TILBURY                          214TH\n",
            "103        IBEX                        226TH                          223RD\n",
            "104        IBEX                        223RD                          221ST\n",
            "105        IBEX                        221ST                   CIVIC CENTER\n",
            "106       JOLIE                        226TH                          223RD\n",
            "107       JOLIE                        223RD                          221ST\n",
            "108       JOLIE                        221ST                   CIVIC CENTER\n",
            "109        JUAN                        226TH                          223RD\n",
            "110        JUAN                        223RD                          221ST\n",
            "111        JUAN                        221ST                   CIVIC CENTER\n",
            "113        JUAN                       CARSON                          214TH\n",
            "114        JUAN                 CENTRALIA ST                            END\n",
            "115      NORWLK                 CENTRALIA ST                          211TH\n",
            "116      NORWLK                        214TH                          211TH\n",
            "117      NORWLK                        211TH                          214TH\n",
            "118      NORWLK                      TILBURY                          214TH\n",
            "119      NORWLK                        214TH                        TILBURY\n",
            "120      NORWLK     BEGIN AC (85' N/ CARSON)                        TILBURY\n",
            "121      NORWLK                      TILBURY        END AC (200' N/ CARSON)\n",
            "122      NORWLK                       CARSON        END PCC (85' N/ CARSON)\n",
            "123      NORWLK   BEGIN PCC (200' N/ CARSON)                         CARSON\n",
            "124      NORWLK   BEGIN PCC (250' S/ CARSON)                         CARSON\n",
            "125      NORWLK                       CARSON        END PCC (85' S/ CARSON)\n",
            "126      NORWLK                 CIVIC CENTER        END AC (250' S/ CARSON)\n",
            "127      NORWLK     BEGIN AC (85' S/ CARSON)                   CIVIC CENTER\n",
            "128      NORWLK                        221ST                   CIVIC CENTER\n",
            "129      NORWLK                 CIVIC CENTER                          221ST\n",
            "130      NORWLK                        223RD                          221ST\n",
            "131      NORWLK                        221ST                          223RD\n",
            "132      NORWLK                        226TH                          223RD\n",
            "133      NORWLK                        223RD                          226TH\n",
            "134       PIONE             SOUTH CITY LIMIT                          223RD\n",
            "135       PIONE                        223RD                          221ST\n",
            "136       PIONE                        221ST                   CIVIC CENTER\n",
            "139       SEINE                        223RD                          221ST\n",
            "140       SEINE                        226TH                          223RD\n",
            "141       SEINE                        221ST                   CIVIC CENTER\n",
            "146       VIOLE                        226TH                          223RD\n",
            "147       VIOLE                        223RD                          221ST\n",
            "148       VIOLE                        221ST                   CIVIC CENTER\n",
            "WARNING:root:Skipping row 57 in final output with None or empty geometry.\n",
            "WARNING:root:Skipping row 58 in final output with None or empty geometry.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete. Check processing_log.txt for detailed information.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import LineString, Point, MultiPoint\n",
        "import numpy as np\n",
        "from thefuzz import process\n",
        "import geopy.distance\n",
        "import simplekml\n",
        "import os\n",
        "import logging\n",
        "import shutil\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='processing_log.txt', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def preprocess_street_name(name):\n",
        "    if name is None:\n",
        "        return ''\n",
        "    name = str(name).upper()\n",
        "    name = name.replace('STREET', 'ST').replace('AVENUE', 'AVE').replace('BOULEVARD', 'BLVD')\n",
        "    return ' '.join(word for word in name.split() if word not in ['THE', 'OF', 'AND'])\n",
        "\n",
        "def normalize_street_name(name):\n",
        "    if name is None:\n",
        "        return ''\n",
        "    return ''.join([c for c in str(name) if not c.isdigit()]).strip()\n",
        "\n",
        "def get_partial_match(query, choices, threshold=70):\n",
        "    if not query:\n",
        "        return None\n",
        "    query = preprocess_street_name(normalize_street_name(query))\n",
        "    processed_choices = {preprocess_street_name(normalize_street_name(k)): k for k in choices if k is not None}\n",
        "\n",
        "    direction_suffixes = ['NB', 'SB', 'EB', 'WB']\n",
        "    query_base = query\n",
        "    for suffix in direction_suffixes:\n",
        "        if query.endswith(suffix):\n",
        "            query_base = query[:-len(suffix)].strip()\n",
        "            break\n",
        "\n",
        "    if query in processed_choices:\n",
        "        return processed_choices[query]\n",
        "\n",
        "    for processed, original in processed_choices.items():\n",
        "        if query_base in processed or processed in query_base:\n",
        "            return original\n",
        "\n",
        "    matches = process.extractBests(query, processed_choices.keys(), score_cutoff=threshold)\n",
        "    if matches:\n",
        "        return processed_choices[matches[0][0]]\n",
        "\n",
        "    return None\n",
        "\n",
        "def create_linestring(row):\n",
        "    points = [(row['BEGIN LONGITUDE'], row['BEGIN LATITUDE'])]\n",
        "    if row['MIDDLE POINTS']:\n",
        "        for point in row['MIDDLE POINTS'].split('; '):\n",
        "            lat, lon = map(float, point.split(','))\n",
        "            points.append((lon, lat))\n",
        "    points.append((row['END LONGITUDE'], row['END LATITUDE']))\n",
        "    return LineString(points)\n",
        "\n",
        "def get_distance(point1, point2):\n",
        "    point1_xy = (point1.y, point1.x)\n",
        "    point2_xy = (point2.y, point2.x)\n",
        "    return geopy.distance.geodesic(point1_xy, point2_xy).feet\n",
        "\n",
        "def find_intersection(line1, line2, buffer_distance=1e-4):\n",
        "    if line1.is_empty or line2.is_empty:\n",
        "        return None\n",
        "    buffered_line1 = line1.buffer(buffer_distance)\n",
        "    buffered_line2 = line2.buffer(buffer_distance)\n",
        "    intersection = buffered_line1.intersection(buffered_line2)\n",
        "    if not intersection.is_empty:\n",
        "        if isinstance(intersection, MultiPoint):\n",
        "            return intersection.centroid\n",
        "        return intersection.centroid\n",
        "    return None\n",
        "\n",
        "def split_line_between_points(line, from_point, to_point):\n",
        "    if line.is_empty:\n",
        "        return None\n",
        "    if line.project(from_point) > line.project(to_point):\n",
        "        from_point, to_point = to_point, from_point\n",
        "    coords = list(line.coords)\n",
        "    from_index = find_nearest_index(coords, from_point)\n",
        "    to_index = find_nearest_index(coords, to_point)\n",
        "    from_index = max(0, min(from_index, len(coords) - 1))\n",
        "    to_index = max(0, min(to_index, len(coords) - 1))\n",
        "    if abs(to_index - from_index) < 2:\n",
        "        logging.warning(f\"Not enough coordinates to split line: from {from_point} to {to_point}\")\n",
        "        return line\n",
        "    split_coords = coords[from_index:to_index + 1]\n",
        "    return LineString(split_coords)\n",
        "\n",
        "def find_nearest_index(coords, point, tolerance=1e-9):\n",
        "    distances = np.array([get_distance(Point(lon, lat), point) for lon, lat in coords])\n",
        "    return np.argmin(distances)\n",
        "\n",
        "# Manual corrections dictionary\n",
        "manual_corrections = {\n",
        "    \"211TH ST\": \"211TH\", \"212TH ST\": \"212TH\", \"213TH ST\": \"213TH\", \"214TH ST\": \"214TH\",\n",
        "    \"215TH ST\": \"215TH\", \"216TH ST\": \"216TH\", \"221ST ST\": \"221ST\", \"222ND ST\": \"222ND\",\n",
        "    \"223RD ST\": \"223RD\", \"224TH ST\": \"224TH\", \"226TH ST\": \"226TH\",\n",
        "    \"ALLEY E/ NORWALK BLVD\": \"ALY010\", \"ALLEY S/ CARSON ST\": \"ALY030\", \"ALLEY W/ NORWALK BLVD\": \"ALY020\",\n",
        "    \"ALLEY S/ 214TH ST\": \"ALY060\", \"ALLEY S/ 215TH ST\": \"ALY050\", \"ALLEY S/ 216TH ST\": \"ALY040\",\n",
        "    \"ARLINE AVE\": \"ARLIN\", \"BELSHIRE AVE\": \"BELSH\", \"BLOOMFIELD AVE\": \"BLOOM\",\n",
        "    \"BRITTAIN ST\": \"BRITT\", \"CANADA DR\": \"CANAD\", \"CARSON ST\": \"CARSN\",\n",
        "    \"CIVIC CENTER DR\": \"CIVIC\", \"CLARETTA AVE\": \"CLARE\", \"CLARKDALE AVE\": \"CLARK\",\n",
        "    \"CORTNER AVE\": \"CORTN\", \"DEVLIN AVE\": \"DEVLI\", \"ELAINE AVE\": \"ELAIN\",\n",
        "    \"FARLOW ST\": \"FARLO\", \"FUNSTON AVE\": \"FUNST\", \"HAWAIIAN AVE\": \"HAWAI\",\n",
        "    \"HORST AVE\": \"HORST\", \"IBEX AVE\": \"IBEX\", \"JOLIET AVE\": \"JOLIE\",\n",
        "    \"JUAN AVE\": \"JUAN\", \"NORWALK BLVD\": \"NORWLK\", \"PIONEER BLVD\": \"PIONE\",\n",
        "    \"SCHULTZE DR\": \"SCHUL\", \"SEINE AVE\": \"SEINE\", \"TILBURY ST\": \"TILBU\",\n",
        "    \"VERNE AVE\": \"VERNE\", \"VIOLETA AVE\": \"VIOLE\", \"WARDHAM AVE\": \"WARDH\",\n",
        "    \"NORWALK CHANNEL\": \"NORWLK\", \"CITY LIMIT\": \"CITY LIMITS\", \"END\": \"END\",\n",
        "    \"CENTRALIA\": \"CENTRALIA ST\"\n",
        "}\n",
        "\n",
        "# Read input files\n",
        "input_shapefile = r\"/content/Output/roads_with_coordinates.shp\"\n",
        "input_gdf = gpd.read_file(input_shapefile)\n",
        "input_crs = input_gdf.crs\n",
        "\n",
        "# Process and merge segments\n",
        "marged_seg = merge_segments(df_shapefile)\n",
        "marged_seg = marged_seg.rename(columns={'FullName': 'STREET NAME'})\n",
        "marged_seg['STREET NAME'] = marged_seg['STREET NAME'].str.upper()\n",
        "marged_seg['geometry'] = marged_seg.apply(create_linestring, axis=1)\n",
        "gdf_lines = gpd.GeoDataFrame(marged_seg, geometry='geometry', crs=input_crs)\n",
        "\n",
        "street_lines = {row['STREET NAME']: row['geometry'] for idx, row in gdf_lines.iterrows() if row['STREET NAME'] is not None}\n",
        "\n",
        "# Initialize DataFrame for split lines\n",
        "all_split_lines_df = pd.DataFrame(columns=['StreetID', 'SectionID', 'STREET NAME', 'FROM', 'TO',\n",
        "                                           'Functional Class', 'Surface Type', 'Lanes', 'Length', 'Width', 'Area', 'geometry'])\n",
        "\n",
        "skipped_rows = []\n",
        "\n",
        "# Initialize counters\n",
        "total_rows = len(df_section)\n",
        "processed_rows = 0\n",
        "skipped_rows_count = 0\n",
        "\n",
        "# Process each section\n",
        "for index, row in df_section.iterrows():\n",
        "    logging.info(f\"Processing row {index}: {row['Name']} from {row['From']} to {row['To']}\")\n",
        "\n",
        "    main_line_name = manual_corrections.get(row[\"Name\"], row[\"Name\"])\n",
        "    from_street = manual_corrections.get(row['From'], row['From'])\n",
        "    to_street = manual_corrections.get(row['To'], row['To'])\n",
        "\n",
        "    direction_suffix = ''\n",
        "    for suffix in ['NB', 'SB', 'EB', 'WB']:\n",
        "        if main_line_name.endswith(suffix):\n",
        "            direction_suffix = suffix\n",
        "            main_line_name = main_line_name[:-len(suffix)].strip()\n",
        "            break\n",
        "\n",
        "    main_line_geometry = get_partial_match(main_line_name, street_lines.keys())\n",
        "    from_line_geometry = get_partial_match(from_street, street_lines.keys())\n",
        "    to_line_geometry = get_partial_match(to_street, street_lines.keys())\n",
        "\n",
        "    if main_line_geometry and from_line_geometry and to_line_geometry:\n",
        "        main_line_geometry = street_lines[main_line_geometry]\n",
        "        from_line_geometry = street_lines[from_line_geometry]\n",
        "        to_line_geometry = street_lines[to_line_geometry]\n",
        "\n",
        "        if main_line_geometry.is_empty or from_line_geometry.is_empty or to_line_geometry.is_empty:\n",
        "            logging.warning(f\"Empty geometry found for {main_line_name}{direction_suffix}, using full line.\")\n",
        "            temp_split_lines_df = pd.DataFrame({\n",
        "                'StreetID': [row['StreetID']],\n",
        "                'SectionID': [row['SectionID']],\n",
        "                'STREET NAME': [f\"{main_line_name}{direction_suffix}\"],\n",
        "                'FROM': [from_street],\n",
        "                'TO': [to_street],\n",
        "                'Functional Class': [row['Functional Class']],\n",
        "                'Surface Type': [row['Surface Type']],\n",
        "                'Lanes': [row['Lanes']],\n",
        "                'Length': [row['Length']],\n",
        "                'Width': [row['Width']],\n",
        "                'Area': [row['Area']],\n",
        "                'geometry': [main_line_geometry]\n",
        "            })\n",
        "            all_split_lines_df = pd.concat([all_split_lines_df, temp_split_lines_df], ignore_index=True)\n",
        "            processed_rows += 1\n",
        "            continue\n",
        "\n",
        "        from_intersection = find_intersection(main_line_geometry, from_line_geometry)\n",
        "        to_intersection = find_intersection(main_line_geometry, to_line_geometry)\n",
        "\n",
        "        logging.info(f\"From Intersection: {from_intersection}\")\n",
        "        logging.info(f\"To Intersection: {to_intersection}\")\n",
        "\n",
        "        if from_intersection and to_intersection:\n",
        "            try:\n",
        "                split_line = split_line_between_points(main_line_geometry, from_intersection, to_intersection)\n",
        "\n",
        "                temp_split_lines_df = pd.DataFrame({\n",
        "                    'StreetID': [row['StreetID']],\n",
        "                    'SectionID': [row['SectionID']],\n",
        "                    'STREET NAME': [f\"{main_line_name}{direction_suffix}\"],\n",
        "                    'FROM': [from_street],\n",
        "                    'TO': [to_street],\n",
        "                    'Functional Class': [row['Functional Class']],\n",
        "                    'Surface Type': [row['Surface Type']],\n",
        "                    'Lanes': [row['Lanes']],\n",
        "                    'Length': [row['Length']],\n",
        "                    'Width': [row['Width']],\n",
        "                    'Area': [row['Area']],\n",
        "                    'geometry': [split_line]\n",
        "                })\n",
        "                all_split_lines_df = pd.concat([all_split_lines_df, temp_split_lines_df], ignore_index=True)\n",
        "                processed_rows += 1\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error splitting line for {main_line_name}{direction_suffix}: {str(e)}\")\n",
        "                skipped_rows_count += 1\n",
        "                skipped_rows.append({'STREET NAME': f\"{main_line_name}{direction_suffix}\", 'FROM': from_street, 'TO': to_street, 'Reason': f'Error splitting line: {str(e)}'})\n",
        "        else:\n",
        "            logging.warning(f\"Not enough intersection points found for {main_line_name}{direction_suffix}, using full line.\")\n",
        "            temp_split_lines_df = pd.DataFrame({\n",
        "                'StreetID': [row['StreetID']],\n",
        "                'SectionID': [row['SectionID']],\n",
        "                'STREET NAME': [f\"{main_line_name}{direction_suffix}\"],\n",
        "                'FROM': [from_street],\n",
        "                'TO': [to_street],\n",
        "                'Functional Class': [row['Functional Class']],\n",
        "                'Surface Type': [row['Surface Type']],\n",
        "                'Lanes': [row['Lanes']],\n",
        "                'Length': [row['Length']],\n",
        "                'Width': [row['Width']],\n",
        "                'Area': [row['Area']],\n",
        "                'geometry': [main_line_geometry]\n",
        "            })\n",
        "            all_split_lines_df = pd.concat([all_split_lines_df, temp_split_lines_df], ignore_index=True)\n",
        "            processed_rows += 1\n",
        "    else:\n",
        "        logging.error(f\"Unrecognized street name(s): {main_line_name}{direction_suffix}, {from_street}, {to_street}. Skipping.\")\n",
        "        skipped_rows_count += 1\n",
        "        skipped_rows.append({'STREET NAME': f\"{main_line_name}{direction_suffix}\", 'FROM': from_street, 'TO': to_street, 'Reason': 'Unrecognized street name'})\n",
        "\n",
        "# Log the results after processing\n",
        "logging.info(f\"Total rows: {total_rows}\")\n",
        "logging.info(f\"Processed rows: {processed_rows}\")\n",
        "logging.info(f\"Skipped rows: {skipped_rows_count}\")\n",
        "\n",
        "# Log the DataFrame information at various stages\n",
        "logging.info(f\"Rows in all_split_lines_df: {len(all_split_lines_df)}\")\n",
        "\n",
        "# Create 'StreetID - SectionID' column\n",
        "all_split_lines_df['StreetID - SectionID'] = all_split_lines_df['StreetID'].astype(str) + ' - ' + all_split_lines_df['SectionID'].astype(str)\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['StreetID', 'SectionID', 'StreetID - SectionID', 'STREET NAME', 'FROM', 'TO',\n",
        "                'Functional Class', 'Surface Type', 'Lanes', 'Length', 'Width', 'Area', 'geometry']\n",
        "all_split_lines_df = all_split_lines_df[column_order]\n",
        "\n",
        "# Create GeoDataFrame and save as shapefile\n",
        "output_directory = r\"/content/Output/Split Output/Split Shapefile\"\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "OUTPUT_MERGED_SHAPEFILE = os.path.join(output_directory, \"output_shapefile_with_attributes.shp\")\n",
        "all_split_lines_gdf = gpd.GeoDataFrame(all_split_lines_df, geometry='geometry', crs=input_crs)\n",
        "all_split_lines_gdf.to_file(OUTPUT_MERGED_SHAPEFILE, driver='ESRI Shapefile')\n",
        "logging.info(f\"Shapefile with reordered columns has been saved to {OUTPUT_MERGED_SHAPEFILE}\")\n",
        "\n",
        "# Create KMZ file\n",
        "OUTPUT_KMZ_MERGED_SEGMENTS = os.path.join(output_directory, \"output_merged_segments.kmz\")\n",
        "kml = simplekml.Kml()\n",
        "\n",
        "for idx, row in all_split_lines_gdf.iterrows():\n",
        "    if row['geometry'] is None or row['geometry'].is_empty:\n",
        "        logging.warning(f\"Skipping row {idx} with None or empty geometry.\")\n",
        "        skipped_rows.append({'STREET NAME': row['STREET NAME'], 'FROM': row['FROM'], 'TO': row['TO'], 'Reason': 'None or empty geometry'})\n",
        "        continue\n",
        "\n",
        "    linestring = kml.newlinestring(name=row['STREET NAME'])\n",
        "    linestring.coords = list(row['geometry'].coords)\n",
        "\n",
        "    for column_name, value in row.items():\n",
        "        if column_name != 'geometry':\n",
        "            linestring.extendeddata.schemadata.newsimpledata(column_name, str(value))\n",
        "\n",
        "kml.savekmz(OUTPUT_KMZ_MERGED_SEGMENTS)\n",
        "logging.info(f\"KMZ file has been saved to {OUTPUT_KMZ_MERGED_SEGMENTS}\")\n",
        "\n",
        "# Save skipped rows\n",
        "skipped_rows_df = pd.DataFrame(skipped_rows)\n",
        "OUTPUT_SKIPPED_ROWS_EXCEL = os.path.join(output_directory, \"skipped_rows.xlsx\")\n",
        "skipped_rows_df.to_excel(OUTPUT_SKIPPED_ROWS_EXCEL, index=False)\n",
        "logging.info(f\"Skipped rows have been saved to {OUTPUT_SKIPPED_ROWS_EXCEL}\")\n",
        "\n",
        "# Clean The Output\n",
        "none_values = all_split_lines_df[all_split_lines_df['geometry'].notna()]\n",
        "logging.info(f\"Rows after removing null geometries: {len(none_values)}\")\n",
        "\n",
        "final_df = none_values[none_values['geometry'] != 'GEOMETRYCOLLECTION EMPTY']\n",
        "logging.info(f\"Rows in final_df: {len(final_df)}\")\n",
        "\n",
        "# Save final output\n",
        "final_output_directory = \"/content/Output/Final Output\"\n",
        "os.makedirs(final_output_directory, exist_ok=True)\n",
        "output_shapefile_path = os.path.join(final_output_directory, \"output_shape.shp\")\n",
        "output_kmz_path = os.path.join(final_output_directory, \"output_shape.kmz\")\n",
        "\n",
        "# Save the final GeoDataFrame as a shapefile\n",
        "final_gdf = gpd.GeoDataFrame(final_df, geometry='geometry', crs='EPSG:4326')\n",
        "logging.info(f\"Rows in final GeoDataFrame: {len(final_gdf)}\")\n",
        "\n",
        "final_gdf.to_file(output_shapefile_path)\n",
        "logging.info(f\"Final shapefile saved with {len(final_gdf)} rows\")\n",
        "\n",
        "# Additional check for duplicate geometries\n",
        "duplicate_geometries = final_gdf[final_gdf.duplicated(subset='geometry', keep=False)]\n",
        "logging.info(f\"Number of rows with duplicate geometries: {len(duplicate_geometries)}\")\n",
        "if len(duplicate_geometries) > 0:\n",
        "    logging.warning(\"Duplicate geometries found. This may result in fewer rows in the final shapefile.\")\n",
        "    logging.warning(duplicate_geometries[['STREET NAME', 'FROM', 'TO']].to_string())\n",
        "\n",
        "# Create a final KMZ file\n",
        "final_kml = simplekml.Kml()\n",
        "\n",
        "for idx, row in final_gdf.iterrows():\n",
        "    if row['geometry'] is None or row['geometry'].is_empty:\n",
        "        logging.warning(f\"Skipping row {idx} in final output with None or empty geometry.\")\n",
        "        continue\n",
        "\n",
        "    linestring = final_kml.newlinestring(name=row['STREET NAME'])\n",
        "    linestring.coords = list(row['geometry'].coords)\n",
        "\n",
        "    for column_name, value in row.items():\n",
        "        if column_name != 'geometry':\n",
        "            linestring.extendeddata.schemadata.newsimpledata(column_name, str(value))\n",
        "\n",
        "# Save the final KMZ file\n",
        "final_kml.savekmz(output_kmz_path)\n",
        "logging.info(f\"Final KMZ file has been saved to {output_kmz_path}\")\n",
        "\n",
        "# Create a zip file of the entire Output folder\n",
        "output_zip_path = \"/content/Output.zip\"\n",
        "shutil.make_archive(\"/content/Output\", 'zip', \"/content/Output\")\n",
        "logging.info(f\"All output has been zipped to {output_zip_path}\")\n",
        "\n",
        "# Print summary\n",
        "logging.info(\"\\nSummary:\")\n",
        "logging.info(f\"Total rows in input: {total_rows}\")\n",
        "logging.info(f\"Successfully processed rows: {len(final_df)}\")\n",
        "logging.info(f\"Skipped rows: {len(skipped_rows)}\")\n",
        "logging.info(f\"\\nCheck {OUTPUT_SKIPPED_ROWS_EXCEL} for details on skipped rows.\")\n",
        "logging.info(f\"\\nFinal output is available in {final_output_directory}\")\n",
        "logging.info(f\"All output files are zipped in {output_zip_path}\")\n",
        "\n",
        "print(\"\\nProcessing complete. Check processing_log.txt for detailed information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Fc_LcXfp-hR"
      },
      "outputs": [],
      "source": [
        "# Clean The Output\n",
        "none_values = all_split_lines_df[all_split_lines_df['geometry'].notna()]\n",
        "final_df = none_values[none_values['geometry']!= 'GEOMETRYCOLLECTION EMPTY']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Add Other Related Attributes"
      ],
      "metadata": {
        "id": "wwEmNjFIXdXw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DT3kIu5LXkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8mTFXcjhXkQh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHJ7gW5cp-hR"
      },
      "source": [
        "### Save to Shapefile and KML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmHF6fQRp-hR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26526238-b3d7-4071-f660-ab4a70e0aae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-f97a49d4742b>:22: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  gdf.to_file(output_shapefile_path)\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'StreetID - SectionID' to 'StreetID -'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'STREET NAME' to 'STREET NAM'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Functional Class' to 'Functional'\n",
            "WARNING:fiona._env:Normalized/laundered field name: 'Surface Type' to 'Surface Ty'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapefile has been saved to /content/Output/Final Output/output_shape.shp\n",
            "KMZ file has been saved to /content/Output/Final Output/output_shape.kmz\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import LineString\n",
        "import simplekml\n",
        "import os\n",
        "\n",
        "# Assuming final_df is your DataFrame with necessary data\n",
        "# Ensure 'geometry' column is present and convert DataFrame to GeoDataFrame\n",
        "if 'geometry' not in final_df.columns:\n",
        "    final_df['geometry'] = final_df.apply(lambda row: LineString([(row['BEGIN LONGITUDE'], row['BEGIN LATITUDE']),\n",
        "                                                                  (row['END LONGITUDE'], row['END LATITUDE'])]), axis=1)\n",
        "\n",
        "gdf = gpd.GeoDataFrame(final_df, geometry='geometry', crs='EPSG:4326')\n",
        "\n",
        "# Define the output directory and ensure it exists\n",
        "output_directory = \"/content/Output/Final Output\"\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "output_shapefile_path = os.path.join(output_directory, \"output_shape.shp\")\n",
        "output_kmz_path = os.path.join(output_directory, \"output_shape.kmz\")\n",
        "\n",
        "# Save the GeoDataFrame as a shapefile\n",
        "gdf.to_file(output_shapefile_path)\n",
        "print(f\"Shapefile has been saved to {output_shapefile_path}\")\n",
        "\n",
        "# Create a KMZ file\n",
        "kml = simplekml.Kml()\n",
        "\n",
        "for idx, row in gdf.iterrows():\n",
        "    linestring = kml.newlinestring(name=row['STREET NAME'])\n",
        "    linestring.coords = list(row['geometry'].coords)\n",
        "\n",
        "    # Add extended data to the placemark\n",
        "    for column_name, value in row.items():\n",
        "        if column_name != 'geometry':\n",
        "            linestring.extendeddata.schemadata.newsimpledata(column_name, str(value))\n",
        "\n",
        "# Save the KMZ file\n",
        "kml.savekmz(output_kmz_path)\n",
        "print(f\"KMZ file has been saved to {output_kmz_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Output.zip /content/Output"
      ],
      "metadata": {
        "id": "qTZNG7iVEOVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c3599a-da9f-4be8-ddf0-52f37d6e5086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Output/ (stored 0%)\n",
            "  adding: content/Output/roads_with_coordinates.cpg (stored 0%)\n",
            "  adding: content/Output/Split Output/ (stored 0%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/ (stored 0%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_shapefile_with_attributes.cpg (stored 0%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_shapefile_with_attributes.dbf (deflated 97%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/skipped_rows.xlsx (deflated 10%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/Split Output/ (stored 0%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_shapefile_with_attributes.shx (deflated 53%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_shapefile_with_attributes.prj (deflated 17%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_merged_segments.kmz (deflated 1%)\n",
            "  adding: content/Output/Split Output/Split Shapefile/output_shapefile_with_attributes.shp (deflated 87%)\n",
            "  adding: content/Output/Split Output/df_section_inspect.xlsx (deflated 4%)\n",
            "  adding: content/Output/roads_with_coordinates.dbf (deflated 95%)\n",
            "  adding: content/Output/Merged Output/ (stored 0%)\n",
            "  adding: content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.shp (deflated 55%)\n",
            "  adding: content/Output/Merged Output/output_excel_merged_segments.xlsx (deflated 6%)\n",
            "  adding: content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.cpg (stored 0%)\n",
            "  adding: content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.dbf (deflated 94%)\n",
            "  adding: content/Output/Merged Output/output_merged_segments.kmz (deflated 1%)\n",
            "  adding: content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.shx (deflated 57%)\n",
            "  adding: content/Output/Merged Output/Merged Outputoutput_shapefile_merged_segments.prj (deflated 17%)\n",
            "  adding: content/Output/Final Output/ (stored 0%)\n",
            "  adding: content/Output/Final Output/output_shape.shx (deflated 53%)\n",
            "  adding: content/Output/Final Output/output_shape.dbf (deflated 97%)\n",
            "  adding: content/Output/Final Output/output_shape.cpg (stored 0%)\n",
            "  adding: content/Output/Final Output/output_shape.shp (deflated 87%)\n",
            "  adding: content/Output/Final Output/output_shape.kmz (deflated 1%)\n",
            "  adding: content/Output/Final Output/output_shape.prj (deflated 17%)\n",
            "  adding: content/Output/roads_with_coordinates.shx (deflated 62%)\n",
            "  adding: content/Output/roads_with_coordinates.shp (deflated 66%)\n",
            "  adding: content/Output/roads_with_coordinates.prj (deflated 17%)\n",
            "  adding: content/Output/coordinates.xlsx (deflated 6%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}